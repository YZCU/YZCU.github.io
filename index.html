<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />
<link rel="icon" href="./img/heart.ico">
<title>Yuzeng Chen - WHU</title>
</head>
<body>

<div class="menu"> <a href="#home">Home</a>
<a href="#education">Experience</a>
<a href="#publications">Publications</a>
<a href="#services">Services</a>
<a href="#awards">Awards</a>
</div>

<a id="home" class="anchor"></a>
<div id="container">
<div class="container">
<div id="toptitle">
<h1>Yuzeng Chen's Homepage: </h1>
</div>
    
<table class="imgtable"><tr><td>
<!--
<a href="./"><img src="./img/cyz.jpg" alt="" height="250px" width="333px"/></a>&nbsp;</td>
-->
<a href="./"><img src="./img/cyz.jpg" alt="" height="250px" width="333px" style="border-radius: 20px;"/></a>&nbsp;

<td align="left"><p><a href="./img/"><font size="4">Yuzeng Chen (é™ˆç‰å¢)</font></a><br/>
<i> Ph.D. Candidate at Wuhan University, Wuhan.</i><br />
<i> Email: yuzeng_chen@whu.edu.cn</i><br />

    
<br><br>
<a href="https://en.whu.edu.cn/" target="_blank">Wuhan University | æ­¦æ±‰å¤§å­¦</a><br>
<a href="http://main.sgg.whu.edu.cn/" target="_blank">School of Geodesy and Geomatics | æµ‹ç»˜å­¦é™¢</a><br>
<a href="http://hts.sgg.whu.edu.cn/" target="_blank">Institute of Aerospace Survey | èˆªç©ºèˆªå¤©æµ‹ç»˜ç ”ç©¶æ‰€</a><br>
<br />

</i></font>&nbsp;<br />
[<a href="https://github.com/YZCU" target="_blank">GitHub</a>]
[<a href="https://scholar.google.com/citations?user=f6ehjBkAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>]
[<a href="./img/weixin.jpg" target="_blank">WeChat</a>]
<br />

<!--
<font color="#FF7F00">â™ª Hopefully something good will happen for all of us â™ª å®‰é™åœ°å®ˆä½æ—¶å…‰ï¼Œæ‰“ç£¨å²æœˆ â™ª</font>
    -->
    
<font color="#FF7F00">â™ªâ™ª Hopefully, something great will come for all of us. â™ªâ™ª</font>
<!--
    -->
</p>
</td></tr></table>

<h2>Biography</h2>
<p>Yuzeng Chen is a Ph.D. candidate at <a href="https://en.whu.edu.cn/">Wuhan University</a>, is supervised by Prof. <a href="http://qqyuan.users.sgg.whu.edu.cn/" target="_blank"><font color="#1772d0">Qiangqiang Yuan (è¢å¼ºå¼º)</font></a> and <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html" target="_blank"><font color="#1772d0">Liangpei Zhang (å¼ è‰¯åŸ¹)</font></a>. He received his master in Central South University, School of Geosciences and info-physics. He received his bachelor in Southwest University of Science and Technology. Drawing upon the realms of remote sensing image/video processing and computer vision.
<li> <b>Remote Sensing Information Processing:</b> Hyperspectral Remote Sensing</li>
<li> <b>Computer Vision:</b> Remote Sensing/Hyperspectral Image/Video Object Detection/Tracking, High-level Vision</li>
<li> <b>Machine Learning:</b> Combine Model and Data-Driven Approach</li>
</p>

<h2>News</h2>
<ul>
<li><font color="black">(05/2025)</font> One paper <a href= "https://www.sciencedirect.com/science/article/pii/S0924271624000856" target="_blank">ProFiT: A Prompt-Guided Frequency-Aware Filtering and Template-Enhanced Interaction Framework for Hyperspectral Video Tracking</a> has been accepted by ISPRS.</li>
<li><font color="black">(02/2025)</font> One co-author paper <a href= "https://ieeexplore.ieee.org/document/10918606" target="_blank">Multi-Axis Feature Diversity Enhancement for Remote Sensing Video Super-Resolution</a> has been accepted by TIP.</li>
<li><font color="black">(01/2025)</font> I was supported by the the first session of the China Association for Science and Technology Young Talent Uplift Project PhD program | ğŸ‰ <a href= "https://mp.weixin.qq.com/s/KhozoDHnFoNAwJiH4BLRRQ" target="_blank">å…¥é€‰é¦–å±Šä¸­å›½ç§‘åé’å¹´äººæ‰æ‰˜ä¸¾å·¥ç¨‹åšå£«ç”Ÿä¸“é¡¹è®¡åˆ’</a></li>
<li><font color="black">(12/2024)</font> I got the National Scholarship for Graduate Student | è·åšå£«ç”Ÿå›½å®¶å¥–å­¦é‡‘</li>
<li><font color="black">(12/2024)</font> I was supported by the Basic Research Fund for Young Students of NSFC | ğŸ‰ è·æ‰¹å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´å­¦ç”ŸåŸºç¡€ç ”ç©¶é¡¹ç›®ï¼ˆåšå£«ç ”ç©¶ç”Ÿï¼‰èµ„åŠ©</li>
<li><font color="black">(10/2024)</font> I won the fourth place in the <a href="https://www.hsitracking.com/">Hyperspectral Object Tracking Challenge 2024</a> | è·é«˜å…‰è°±è·Ÿè¸ªæŒ‘æˆ˜èµ›ç¬¬å››</li>
<li><font color="black">(10/2024)</font> Papers <a href= "https://www.sciencedirect.com/science/article/pii/S0924271624000856?via%3Dihub" target="_blank">OOTB</a>, <a href= "https://www.sciencedirect.com/science/article/pii/S1569843224000955?via%3Dihub" target="_blank">REPS</a>, and <a href= "https://ieeexplore.ieee.org/document/10375560" target="_blank">SPIRIT</a> have been selected as ESI Highly Cited Papers (TOP 1%) | ğŸ‰ ä¸‰ç¯‡å·¥ä½œå…¥é€‰é«˜è¢«å¼•</li>


</ul>


<a id="education" class="anchor"></a>
<h2>Education:</h2>
<ul>
    
<li> 
<b>Ph.D.</b> in <a href="https://en.whu.edu.cn/">Wuhan University</a>, <a href="http://main.sgg.whu.edu.cn/" target="_blank">SGG</a>.
<div style="float:right;"><num>2023.09ï½Now</num></div>
&emsp;&emsp;
<b>Supv.:</b> Prof. <a href="http://qqyuan.users.sgg.whu.edu.cn/" target="_blank">Qiangqiang Yuan</a> and Prof. <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html" target="_blank">Liangpei Zhang</a><br>

<li> 
<b>M.S.</b> &ensp;in <a href="https://www.csu.edu.cn/">Central South University</a>, School of Geosciences and Info-Physics.
<div style="float:right;"><div style="font-family: "Times New Roman";"><num>2020.09ï½2023.06</num></div></div>
&emsp;&emsp;
<b>Supv.:</b> Prof. <a href="https://faculty.csu.edu.cn/yqtang/en/index/62721/list/index.htm" target="_blank">Yuqi Tang</a><br>

<li> 
Robot Technology Used for Special Environment Key Laboratory of Sichuan Province.
<div style="float:right;"><div style="font-family: "Times New Roman";"><num>2017.06ï½2020.06</num></div></div>
&emsp;
<b> Supv.:</b> Prof. <a href="https://gmis.swust.edu.cn/TutorIntroduction/TutorInfo.aspx?zjbh=1020001114" target="_blank">Hua Zhang</a> <br>
    
<li> 
<b>B.S.</b> in <a href="https://www.swust.edu.cn/?ynhfkluojqgttmfr">Southwest University of Science and Technology</a>, School of Environment and Resource.
<div style="float:right;"><num>2016.09ï½2020.06</num></div>

    
</ul>

<!--
    -->
    
<!-- <Impact Factor List -->
<script>
var ifif=14.7;
jstars=4.7;
rs=4.2;
tgrs=7.5;
jag=7.6;
isprs=10.6; 
iff=14.7;
ijde=3.7;
tmmif=8.4;
tip=10.8;
</script>
<br />
    
<!-- Publications -->
<a id="publications" class="anchor"></a>
<h2>Publications</h2>
<h3><li>Journals</li></h3>
<table class="imgtable">
    
<!-- paper entry -->
<!-- 

-->
 

    
<tr>
<td><img class="proj_thumb" src="./papers/SSTtrack.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://www.sciencedirect.com/science/article/pii/S1566253524004366" target="_blank"><b>SSTtrack: A Unified Hyperspectral Video Tracking Framework via Modeling Spectral-Spatial-Temporal Conditions</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Qiangqiang Yuan*, Yuqi Tang, Yi Xiao, Jiang He, Te Han, Zhenqi Liu, and Liangpei Zhang<br>
Information Fusion (<b>INF FUS</b>), <num>2025</num><br>
(<num>SCI Q1 Top, IF=<script>document.write(iff)</script></num>)<br>
<num><a href= "https://www.sciencedirect.com/science/article/pii/S1566253524004366" target="_blank">PDF</a> | <a href="https://github.com/YZCU/SSTtrack" target="_blank">Code</a></num>


    
<tr>
<td><img class="proj_thumb" src="./papers/profit.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://www.sciencedirect.com/science/article/pii/S0924271624000856" target="_blank"><b>ProFiT: A Prompt-Guided Frequency-Aware Filtering and Template-Enhanced Interaction Framework for Hyperspectral Video Tracking</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Qiangqiang Yuan*, Yuqi Tang*, Xin Wang, Yi Xiao, Jiang He, Ziyang Lihe, and Xianyu Jin<br>
ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS</b>), <num>2025</num><br>
(<num>SCI Q1 Top, IF=<script>document.write(isprs)</script></num>)<br>
<num><a href= "./attaches/profit.pdf" target="_blank">PDF</a> | <a href="https://github.com/YZCU/ProFiT" target="_blank">Code</a></num>
<!-- 
<num>â­<b><font color="red" size="2">Highly Cited Paper</font></b></num>
-->
</p>
</td>
</tr>   

    
</p>
</td>
</tr> 
    
<tr>
<td><img class="proj_thumb" src="./papers/sens.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://www.sciencedirect.com/science/article/pii/S1566253524001738" target="_blank"><b>SENSE: Hyperspectral Video Object Tracker via Fusing Material and Motion Cues</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Qiangqiang Yuan*, Yuqi Tang*, Yi Xiao, Jiang He, and Zhenqi Liu<br>
Information Fusion (<b>INF FUS</b>), <num>2024</num><br>
(<num>SCI Q1 Top, IF=<script>document.write(iff)</script></num>)<br>
<num><a href= "./attaches/sense.pdf" target="_blank">PDF</a> | <a href="https://github.com/YZCU/SENSE" target="_blank">Code</a></num>
</p>
</td>
</tr> 
    
<tr>
<td><img class="proj_thumb" src="./papers/ootb.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://www.sciencedirect.com/science/article/pii/S0924271624000856" target="_blank"><b>Satellite Video Single Object Tracking: A Systematic Review and An Oriented Object Tracking Benchmark</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Yuqi Tang*, Yi Xiao, Qiangqiang Yuan, Yuwei Zhang, Fengqing Liu, Jiang He, and Liangpei Zhang<br>
ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS</b>), <num>2024</num><br>
(<num>SCI Q1 Top, IF=<script>document.write(isprs)</script></num>)<br>
<num><a href= "./attaches/ootb.pdf" target="_blank">PDF</a> | <a href="https://github.com/YZCU/OOTB" target="_blank">Code</a></num>
<num>â­<b><font color="red" size="2">Highly Cited Paper</font></b></num>
</p>
</td>
</tr>    


<tr>
<td><img class="proj_thumb" src="./papers/phtrack.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10680554" target="_blank"><b>PHTrack: Prompting for Hyperspectral Video Tracking</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Yuqi Tang, Xin Su*, Jie Li*, Yi Xiao, Jiang He, and Qiangqiang Yuan<br>
IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), <num>2024</num><br>
(<num>SCI Q1, IF=<script>document.write(tgrs)</script></num>)<br>
<num><a href= "./attaches/phtrack.pdf" target="_blank">PDF</a> | <a href="https://github.com/YZCU/PHTrack" target="_blank">Code</a></num> 
</p>
</td>
</tr> 

    
<tr>
<td><img class="proj_thumb" src="./papers/spirit.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10375560" target="_blank"><b>SPIRIT: Spectral Awareness Interaction Network With Dynamic Template for Hyperspectral Object Tracking</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Qiangqiang Yuan*, Yuqi Tang, Yi Xiao, Jiang He, and Liangpei Zhang<br>
IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), <num>2024</num><br>
(<num>SCI Q1, IF=<script>document.write(tgrs)</script></num>)<br>
<num><a href= "./attaches/spirit.pdf" target="_blank">PDF</a> | <a href="https://github.com/YZCU/SPIRIT/tree/master/tracking_results" target="_blank">Result</a> â­<b><font color="red" size="2">Highly Cited Paper</font></b></num>
</p>
</td>
</tr> 

    
<tr>
<td><img class="proj_thumb" src="./papers/reps.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://www.sciencedirect.com/science/article/pii/S1569843224000955" target="_blank"><b>REPS: Rotation Equivariant Siamese Network Enhanced by Probability Segmentation for Satellite Video Tracking</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Yuqi Tang*, Qiangqiang Yuan, and Liangpei Zhang<br>
International Journal of Applied Earth Observation and Geoinformation (<b>JAG</b>), <num>2024</num><br>
(<num>SCI Q1 Top, IF=<script>document.write(jag)</script></num>)<br>
<num><a href= "./attaches/reps.pdf" target="_blank">PDF</a> | <a href="https://github.com/YZCU/REPS" target="_blank">Code</a></num>
<num>â­<b><font color="red" size="2">Highly Cited Paper</font></b></num>
</p>
</td>
</tr>


<tr>
<td><img class="proj_thumb" src="./papers/df.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/9803284" target="_blank"><b>Single Object Tracking in Satellite Videos: A Correlation Filter-Based Dual-Flow Tracker</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Yuqi Tang*, Zhiyong Yin, Te Han, Bin Zou, and Huihui Feng<br>
IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>JSTARS</b>), <num>2022</num><br>
(<num>SCI Q1 Top, IF=<script>document.write(jstars)</script></num>)<br>
<num><a href= "./attaches/df.pdf" target="_blank">PDF</a> | <a href="https://github.com/YZCU/DF" target="_blank">Code</a></num>
</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/ramc.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://www.mdpi.com/2072-4292/14/13/3108" target="_blank"><b>RAMC: A Rotation Adaptive Tracker with Motion Constraint for Satellite Video Single-Object Tracking</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Yuqi Tang*, Te Han, Yuwei Zhang, Bin Zou, and Huihui Feng<br>
Remote Sensing (<b>RS</b>), <num>2022</num><br>
(<num>SCI Q1, IF=<script>document.write(rs)</script></num>)<br>
<num><a href= "./attaches/ramc.pdf" target="_blank">PDF</a>  | <a href="https://github.com/YZCU/RAMC" target="_blank">Code</a>
</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/ma.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10918606" target="_blank">Multi-Axis Feature Diversity Enhancement for Remote Sensing Video Super-Resolution</a></p>
<p class="pub_author">Yi Xiao, Qiangqiang Yuan, Kui Jiang, <b>Yuzeng Chen</b>, Shiqi Wang, Chia-Wen Lin<br>
IEEE Transactions on Image Processing (<b>IEEE TIP</b>), <num>2025</num><br>
(<num>SCI Q1, IF=<script>document.write(tip)</script></num>)<br>
<num><a href= "https://ieeexplore.ieee.org/document/10918606" target="_blank">PDF</a> | <a href="https://github.com/XY-boy/MADNet" target="_blank">Code</a>
</num>
</p>
</td>
</tr>
    
    
<tr>
<td><img class="proj_thumb" src="./papers/fmsr.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://arxiv.org/abs/2405.04964" target="_blank">Frequency-Assisted Mamba for Remote Sensing Image Super-Resolution</a></p>
<p class="pub_author">Yi Xiao, Qiangqiang Yuan*, Kui Jiang, <b>Yuzeng Chen</b>, Qiang Zhang, and CW. Lin<br>
IEEE Transactions on Multimedia (<b>IEEE TMM</b>), <num>2024</num><br>
(<num>SCI Q1, IF=<script>document.write(tmmif)</script></num>)<br>
<num><a href= "./attaches/FreMamba.pdf" target="_blank">PDF</a> | <a href="https://github.com/XY-boy/FreMamba" target="_blank">Code</a>
</num>
</p>
</td>
</tr>


    
<tr>
<td><img class="proj_thumb" src="./papers/SDC-GAE.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10517637" target="_blank">SDC-GAE: Structural Difference Compensation Graph Autoencoder for Unsupervised Multimodal Change Detection</a></p>
<p class="pub_author">Te Han, Yuqi Tang*, <b>Yuzeng Chen</b>, et al.<br>
IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), <num>2024</num><br>
(<num>SCI Q1, IF=<script>document.write(tgrs)</script></num>)<br>
<num><a href= "./attaches/SDC-GAE.pdf" target="_blank">PDF</a> | <a href="./attaches/BibTex/SDC-GAE.txt" target="_blank">BibTex</a></num>
</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/gsgm.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://www.tandfonline.com/doi/full/10.1080/17538947.2024.2347457" target="_blank">Global Structure Graph Mapping for Multimodal Change Detection</a></p>
<p class="pub_author">Te Han, Yuqi Tang*, <b>Yuzeng Chen</b>, et al.<br>
International Journal of Digital Earth (<b>IJDE</b>), <num>2024</num><br>
(<num>SCI Q1, IF=<script>document.write(ijde)</script></num>)<br>
<num><a href= "./attaches/gsgm.pdf" target="_blank">PDF</a> | <a href="https://github.com/rshante0426/GSGM" target="_blank">Code</a></num>
</p>
</td>
</tr>
    
</table>

<h3><li>Conferences</li></h3>
<table class="imgtable">
    
<tr>
<td><img class="proj_thumb" src="./papers/hypertdi.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"><a href="https://ieeexplore.ieee.org/document/9883323" target="_blank">Template-Driven Interaction for Hyperspectral Video Object Tracking</a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Qiangqiang Yuan, Yi Xiao.<br>
IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>), <num>2025</num><br>
<num><a href="./attaches/hypertdi.pdf" target="_blank">PDF</a> | <a href= "./attaches/BibTex/hypertdi.txt" target="_blank">BibTex</a></num>
</p>
</td>
</tr>
    
    
<tr>
<td><img class="proj_thumb" src="./papers/HySSTP.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"><a href="https://iopscience.iop.org/article/10.1088/1742-6596/2486/1/012018/meta" target="_blank">HySSTP: Hyperspectral Video Tracker Embedding Multi-Modal Spatial-Spectral-Temporal Features</a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Qiangqiang Yuan.<br>
WHISPERS, <num>2024</num><br>
<num><a href="./attaches/HySSTP.pdf" target="_blank">PDF</a> | <a href= "./attaches/BibTex/HySSTP.txt" target="_blank">BibTex</a></num>
</p>
</td>
</tr>

<!--
<tr>
<td><img class="proj_thumb" src="./papers/smgf.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"><a href="https://iopscience.iop.org/article/10.1088/1742-6596/2486/1/012018/meta" target="_blank">A Ship Monitoring Framework Based on Multimodal Remote Sensing Data</a></p>
<p class="pub_author">Zhiyong Yin, Yuqi Tang, <b>Yuzeng Chen</b>, et al.<br>
Journal of Physics: Conference Series, <num>2023</num><br>
<num><a href="./attaches/smgf.pdf" target="_blank">PDF</a> | <a href= "./attaches/BibTex/smgf.txt" target="_blank">BibTex</a></num>
</p>
</td>
</tr>
-->

<tr>
<td><img class="proj_thumb" src="./papers/TSJFL.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"><a href="https://ieeexplore.ieee.org/document/9883323" target="_blank">Heterogeneous Image Change Detection Based on Two-stage Joint Feature Learning</a></p>
<p class="pub_author">Te Han, Yuqi Tang, <b>Yuzeng Chen</b><br>
IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>), <num>2022</num><br>
<num><a href="./attaches/TSJFL.pdf" target="_blank">PDF</a> | <a href= "./attaches/BibTex/TSJFL.txt" target="_blank">BibTex</a></num>
</p>
</td>
</tr>
    
</table>

<h3><li>Selected Patents:</li></h3>
<table class="imgtable">

<tr>
<td><img class="proj_thumb" src="./papers/patent.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"><a href="./attaches/patent.pdf" target="_blank"><b>A Dynamic Vehicle Target Extraction Method for Satellite Video by Fusing Luminance-Temporal Features</b></a></p>
<p class="pub_author"><b>Yuzeng Chen</b>, Yuqi Tang, et al., <num>2023</num><br>
</p>
</td>
</tr>
    
</table>

<!-- Editor Services Here -->
<a id="services" class="anchor"></a>
<h2>Services</h2>
<p><b>Journal Reviewer:</b></p>
<!-- <font size="3"> -->
<ul>
<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)
<li>IEEE Transactions on Geoscience and Remote Sensing (TGRS)
<li>ISPRS Journal of Photogrammetry and Remote Sensing (ISPRS)
<li>Information Fusion (INFF)
<li>International Journal of Computer Vision (IJCV)
<li>IEEE Transactions on Image Processing (TIP)
</ul>

<!-- Award entry -->
<a id="awards" class="anchor"></a>
<h2>Awards and Honors</h2>
    <ul>
        <li><num>2024</num>, National Scholarship for Graduate Student, Ministry of Education | <a href= "./attaches/awards/guojiang2024.jpg" target="_blank">å›½å®¶å¥–å­¦é‡‘</a></li>
        <li><num>2022</num>, National Scholarship for Graduate Student, Ministry of Education | <a href= "./attaches/awards/guojiang2022.jpg" target="_blank">å›½å®¶å¥–å­¦é‡‘</a></li>
        <li><num>2019</num>, National Scholarship for Graduate Student, Ministry of Education | <a href= "./attaches/awards/guojiang2019.jpg" target="_blank">å›½å®¶å¥–å­¦é‡‘</a></li>
        <li><num>2018</num>, National Scholarship for Graduate Student, Ministry of Education | <a href= "./attaches/awards/guojiang2018.jpg" target="_blank">å›½å®¶å¥–å­¦é‡‘</a></li>
    </ul>

</div>
</div>
</div>
</div>
</body>
</html>
